{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import io\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageOps\n",
    "from keras.applications import DenseNet121, ResNet50\n",
    "from keras.applications.densenet import decode_predictions, preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import BatchNormalization, Dense, Dropout, Flatten, ReLU\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import argmax\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import ShuffleSplit, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints the count of all images.\n",
    "parent_dir = '/Users/Vicente/Downloads/ann/work/Arch/arch_img/'\n",
    "count = 0\n",
    "for subdir, dirs, files in os.walk(parent_dir):\n",
    "    for file in files:\n",
    "        im = str.lower(file)\n",
    "        if im.endswith('.jpg'):\n",
    "            count++\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN (One time process)\n",
    "# Mirrors all images\n",
    "parent_dir = '/Users/Vicente/Downloads/ann/work/Arch/arch_img/'\n",
    "count = 0\n",
    "for subdir, dirs, files in os.walk(parent_dir):\n",
    "    for file in files:\n",
    "        im = str.lower(file)\n",
    "        if im.endswith('.jpg'):\n",
    "            temp = os.path.join(parent_dir, subdir)\n",
    "            image_path = (os.path.join(temp, im))\n",
    "            im = Image.open(image_path)\n",
    "            imf = ImageOps.mirror(im)\n",
    "            nojpg = image_path[:-4]\n",
    "            new_path = (nojpg + \"_mirror.jpg\")\n",
    "            print(new_path)\n",
    "            imf.save(new_path, \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initizalizes the Densenet model and creates the classifier on top.\n",
    "model = DenseNet121(weights='imagenet', include_top=False,\n",
    "                    input_shape=[128, 128, 3])\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[-100:]:\n",
    "    layer.trainable = True\n",
    "flat1 = Flatten()(model.layers[-1].output)\n",
    "D1 = Dense(32, activation='relu')(flat1)\n",
    "B3 = BatchNormalization()(D1)\n",
    "R2 = ReLU()(B3)\n",
    "Dr2 = Dropout(0.5)(R2)\n",
    "D3 = Dense(32, activation='relu')(Dr2)\n",
    "B2 = BatchNormalization()(D3)\n",
    "output = Dense(25, activation='softmax')(B2)\n",
    "model = Model(inputs=model.inputs, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = '/Users/Vicente/Downloads/ann/work/Arch/arch_img/'\n",
    "for subdir, dirs, files in os.walk(parent_dir):\n",
    "    print(subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catagories = {'Palladian architecture': 0,\n",
    "              'Novelty architecture': 1,\n",
    "              'International style': 2,\n",
    "              'Chicago school architecture': 3,\n",
    "              'Beaux-Arts architecture': 4,\n",
    "              'Ancient Egyptian architecture': 5,\n",
    "              'Gothic architecture': 6,\n",
    "              'Tudor Revival architecture': 7,\n",
    "              'Romanesque architecture': 8,\n",
    "              'Colonial architecture': 9,\n",
    "              'American craftsman style': 10,\n",
    "              'Greek Revival architecture': 11,\n",
    "              'Queen Anne architecture': 12,\n",
    "              'Baroque architecture': 13,\n",
    "              'Edwardian architecture': 14,\n",
    "              'Art Nouveau architecture': 15,\n",
    "              'Deconstructivism': 16,\n",
    "              'Bauhaus architecture': 17,\n",
    "              'Georgian architecture': 18,\n",
    "              'Byzantine architecture': 19,\n",
    "              'Postmodern architecture': 20,\n",
    "              'Achaemenid architecture': 21,\n",
    "              'Art Deco architecture': 22,\n",
    "              'American Foursquare architecture': 23,\n",
    "              'Russian Revival architecture': 24}\n",
    "print(type(catagories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# creates a list of all image paths in parent dir\n",
    "all_img_paths = glob.glob(os.path.join(parent_dir, '*.jpg'))\n",
    "parent_dir = '/Users/Vicente/Downloads/ann/work/Arch/arch_img/'\n",
    "for subdir, dirs, files in os.walk(parent_dir):\n",
    "    for file in files:\n",
    "        im = str.lower(file)\n",
    "        if im.endswith('.jpg'):\n",
    "            temp = os.path.join(parent_dir, subdir)\n",
    "            image_path = (os.path.join(temp, im))\n",
    "            all_img_paths.append(image_path)\n",
    "print(len(all_img_paths))\n",
    "print(all_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a matrix with all the processed images ready to be input into the model.\n",
    "\n",
    "IMG_SIZE_X = 128\n",
    "IMG_SIZE_Y = 128\n",
    "IMAGE_SIZE = 128\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "all_img_paths = glob.glob(os.path.join(parent_dir, '*.jpg'))\n",
    "parent_dir = '/Users/Vicente/Downloads/ann/work/Arch/arch_img/'\n",
    "for subdir, dirs, files in os.walk(parent_dir):\n",
    "    for file in files:\n",
    "        im = str.lower(file)\n",
    "        if im.endswith('.jpg'):\n",
    "            temp = os.path.join(parent_dir, subdir)\n",
    "            image_path = (os.path.join(temp, im))\n",
    "            all_img_paths.append(image_path)\n",
    "\n",
    "sample_img_paths = all_img_paths[0:5000]\n",
    "\n",
    "# np.random.shuffle(all_img_paths)\n",
    "final = []\n",
    "count = 0\n",
    "# SWITCH TO ALL IMAGES WHEN READY\n",
    "# could use preprocess_img to not have to use list\n",
    "for img_path in all_img_paths:\n",
    "    print(img_path)\n",
    "    image = Image.open(img_path).resize(\n",
    "        (IMAGE_SIZE, IMAGE_SIZE)).convert('RGB')\n",
    "    image = np.asarray(image)\n",
    "    image = np.reshape(image, (128, 128, 3))\n",
    "    print(image.shape)\n",
    "    # Try with one image. Reshape tries to put it in the shape given.\n",
    "    # Make list of arrays into one big array\n",
    "    final.append(np.asarray(image))\n",
    "    count + +\n",
    "    print(count)\n",
    "\n",
    "print(\"DONE WITH ADDING\")\n",
    "print(type(final))\n",
    "final = np.reshape(final, (-1, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS))\n",
    "print(\"DONE RESHAPING\")\n",
    "print(type(final))\n",
    "final = final / 127.5 - 1\n",
    "print(final.shape)\n",
    "print(final.size)\n",
    "print(len(final))\n",
    "\n",
    "\n",
    "np.save('Final.npy', final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Convert catagory of Arch Data into Numbers\n",
    "cat_list = []\n",
    "for img_path in all_img_paths:\n",
    "    for key in catagories.keys():\n",
    "        if (img_path.find(key) != -1):\n",
    "            cat_list.append(catagories[key])\n",
    "print(cat_list)\n",
    "print(len(cat_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# SWITCH TO y_raw\n",
    "# One hot encodes the catagory matrix\n",
    "y_raw = np.asarray(cat_list)\n",
    "num_classes = len(set(y_raw))\n",
    "ytry = keras.utils.to_categorical(y_raw, num_classes)\n",
    "print(len(ytry))\n",
    "print(ytry)\n",
    "np.save('YSave', ytry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Run to split test data\n",
    "x_raw, X_test, y_try, y_test = train_test_split(\n",
    "    x_raw, ytry, test_size=0.20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all current data\n",
    "np.save('final.npy', x_raw)\n",
    "print('finished')\n",
    "np.save('y_try.npy', y_try)\n",
    "print('finished')\n",
    "np.save('X_test.npy', X_test)\n",
    "print('finished')\n",
    "np.save('y_test.npy', y_test)\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "# Use if just starting\n",
    "x_raw = np.load('final.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use if already running Final from before\n",
    "x_raw = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_try = np.load(\"y_try.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batchsize and epochs\n",
    "batch_size = 32\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile and run model\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "hist = model.fit(x_raw, y_try, batch_size=batch_size,\n",
    "                 epochs=epochs, validation_split=0.1, shuffle=True)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test data\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves model\n",
    "model.save(\"testmodel\")\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_raw, y_train, test_size=0.20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist.history)\n",
    "print(hist.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# undo the onehot encoding\n",
    "arg = (argmax((y_test), axis=1))\n",
    "y_test_cat = []\n",
    "for num in arg:\n",
    "    y_test_cat.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "# Calls the model on raw test images and ranks which prediction was correct. 1 = first, 5 = fifth etc.\n",
    "\n",
    "# Take in Y test\n",
    "total = []\n",
    "count = 0\n",
    "pre1 = []\n",
    "# Take in raw images\n",
    "code = 0\n",
    "i = 0\n",
    "pre = []\n",
    "while i < 25:\n",
    "    pre.append(i)\n",
    "    i++\n",
    "for key in catagories.keys():\n",
    "    for value in pre:\n",
    "        if catagories[key] == value:\n",
    "            pre1.append(key)\n",
    "for image in x_test:\n",
    "    print(count)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    yhat = model.predict(image)\n",
    "    yhat1 = yhat * 1000\n",
    "    predictzip = zip(yhat[0], pre1)\n",
    "    predictset = set(predictzip)\n",
    "    sortedpre = (sorted(predictset))\n",
    "    top5 = sortedpre[-5:]\n",
    "    val = y_test_cat[count]\n",
    "    guess = 6\n",
    "    for key in catagories.keys():\n",
    "        if catagories[key] == val:\n",
    "            for tup in top5:\n",
    "                guess--\n",
    "                if tup[1] == key:\n",
    "                    total.append(guess)\n",
    "    count += 1\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# print percentage of model accuracy depending on how many different predicitons you consider.\n",
    "print(len(total))\n",
    "lentotal = len(total)\n",
    "fifth = total.count(5)\n",
    "print(fifth)\n",
    "fourth = total.count(4)\n",
    "print(fourth)\n",
    "third = total.count(3)\n",
    "print(third)\n",
    "sec = total.count(2)\n",
    "print(sec)\n",
    "one = total.count(1)\n",
    "print(one)\n",
    "top5count = (one + sec + third + fourth+fifth)/lentotal\n",
    "print(\"top5count is equal to:\" + top5count)\n",
    "top3count = (one + sec + third)/lentotal\n",
    "print(\"top3count is equal to:\" + top3count)\n",
    "print(\"top3count is equal to:\" + (one/lentotal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "x_test = np.load('X_test.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "x_raw = np.load(\"final.npy\")\n",
    "y_try = np.load(\"y_try.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_ohe = model.predict(x_test)  # shape=(n_samples, 12)\n",
    "# only necessary if output has one-hot-encoding, shape=(n_samples)\n",
    "y_pred_labels = np.argmax(y_pred_ohe, axis=1)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(\n",
    "    y_true=y_test_cat, y_pred=y_pred_labels)  # shape=(12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pl.matshow(confusion_matrix)\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does work but you have to have already run different cells. I do not want to have to load up final.py again. 6gb of data\n",
    "print(classification_report(y_test_cat, y_pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
